# cli: data-replicator configs/cross_metastore/streaming_tables_defaults.yaml --target-catalogs [catalog_name] --target-schemas [schema1,schema2]
# Steps:
# 1. Create delta share infrastructure in this tool including backup catalog, recipient, shares and shared catalogs with default system generated names.
# 2. Export of source Streaming table backing table as delta table into backup catalog and share.
# 3. Deep clone backup delta table into target Streaming table backing table. Note: For Streaming Table replication, tables need to already exist in target before Deep Clone
# 4. Reconciliate data between source and target Streaming table.

version: "1.0"

replication_group: "streaming_tables_defaults"

source_databricks_connect_config:
  name: "azure"
  host: "https://adb-984752964297111.11.azuredatabricks.net"
  token:
    secret_scope: "test_kr"
    secret_pat: "pat_source"

target_databricks_connect_config:
  name: "aws"
  host: "https://e2-demo-field-eng.cloud.databricks.com"
  token:
    secret_scope: "test_kr"
    secret_pat: "pat_target"

audit_config:
  audit_table: "data_replication.audit.audit_logging"

table_types: ["streaming_table"]
backup_config:
  enabled: true
  create_backup_catalog: true
  create_recipient: true
  create_share: true
  add_to_share: true
replication_config:
  enabled: true
  create_shared_catalog: true
reconciliation_config:
  enabled: true
  create_shared_catalog: true

concurrency:
  max_workers: 5
  timeout_seconds: 1800

retry:
  max_attempts: 2
  retry_delay_seconds: 3
